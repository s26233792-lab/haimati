#!/usr/bin/env python3
"""
API è°ƒç”¨è¯Šæ–­å·¥å…·
ç”¨äºæ’æŸ¥å›¾ç‰‡ç”Ÿæˆé—®é¢˜
"""

import os
import sys
import base64
import json
import requests
from datetime import datetime

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()

# é¢œè‰²è¾“å‡º
class Colors:
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BLUE = '\033[94m'
    END = '\033[0m'

def print_status(message, status="info"):
    """æ‰“å°å¸¦é¢œè‰²çš„çŠ¶æ€ä¿¡æ¯"""
    if status == "success":
        print(f"{Colors.GREEN}âœ“{Colors.END} {message}")
    elif status == "warning":
        print(f"{Colors.YELLOW}âš {Colors.END} {message}")
    elif status == "error":
        print(f"{Colors.RED}âœ—{Colors.END} {message}")
    else:
        print(f"{Colors.BLUE}â„¹{Colors.END} {message}")

def check_api_config():
    """æ£€æŸ¥ API é…ç½®"""
    print("\n" + "="*70)
    print("ğŸ”§ æ£€æŸ¥ API é…ç½®")
    print("="*70)
    
    api_key = os.getenv('NANOBANANA_API_KEY', '')
    api_provider = os.getenv('API_PROVIDER', 'apicore')
    model_name = os.getenv('MODEL_NAME', 'gemini-3-pro-image-preview')
    
    if not api_key:
        print_status("NANOBANANA_API_KEY æœªè®¾ç½®ï¼", "error")
        return False
    
    print_status(f"API Key å·²è®¾ç½® (é•¿åº¦: {len(api_key)})", "success")
    print_status(f"API æä¾›å•†: {api_provider}", "info")
    print_status(f"æ¨¡å‹: {model_name}", "info")
    
    # æ£€æŸ¥ API æ ¼å¼
    API_BASE_URLS = {
        'apicore': 'https://api.apicore.ai/v1',
        'laozhang': 'https://api.laozhang.ai/v1',
        '12ai': 'https://ismaque.org/v1'
    }
    
    base_url = API_BASE_URLS.get(api_provider, API_BASE_URLS['apicore'])
    is_gemini = model_name.startswith('gemini-')
    
    if api_provider == '12ai' and is_gemini:
        api_url = f"{base_url}/models/{model_name}:generateContent"
        api_format = 'gemini'
    else:
        api_url = f"{base_url}/chat/completions"
        api_format = 'openai'
    
    print_status(f"API URL: {api_url}", "info")
    print_status(f"API æ ¼å¼: {api_format}", "info")
    
    return {
        'api_key': api_key,
        'api_url': api_url,
        'api_format': api_format,
        'model_name': model_name
    }

def test_api_connection(config):
    """æµ‹è¯• API è¿æ¥"""
    print("\n" + "="*70)
    print("ğŸŒ æµ‹è¯• API è¿æ¥")
    print("="*70)
    
    try:
        headers = {
            'Authorization': f'Bearer {config["api_key"]}',
            'Content-Type': 'application/json'
        }
        
        # ç®€å•æµ‹è¯•è¯·æ±‚
        if config['api_format'] == 'openai':
            test_payload = {
                "model": config['model_name'],
                "messages": [{"role": "user", "content": "Hi"}],
                "max_tokens": 5
            }
        else:
            test_payload = {
                "contents": [{"parts": [{"text": "Hi"}]}]
            }
        
        print_status(f"å‘é€æµ‹è¯•è¯·æ±‚åˆ°: {config['api_url']}", "info")
        response = requests.post(
            config['api_url'],
            headers=headers,
            json=test_payload,
            timeout=30
        )
        
        print_status(f"å“åº”çŠ¶æ€ç : {response.status_code}", 
                    "success" if response.status_code == 200 else "error")
        
        if response.status_code != 200:
            print_status(f"é”™è¯¯å“åº”: {response.text[:200]}", "error")
            return False
            
        return True
        
    except Exception as e:
        print_status(f"è¿æ¥å¤±è´¥: {e}", "error")
        return False

def test_image_generation(config, test_image_path=None):
    """æµ‹è¯•å›¾ç‰‡ç”Ÿæˆ"""
    print("\n" + "="*70)
    print("ğŸ–¼ï¸ æµ‹è¯•å›¾ç‰‡ç”Ÿæˆ")
    print("="*70)
    
    # å¦‚æœæ²¡æœ‰æä¾›æµ‹è¯•å›¾ç‰‡ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾
    if not test_image_path or not os.path.exists(test_image_path):
        try:
            from PIL import Image
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾ç‰‡
            test_image_path = "test_input.png"
            img = Image.new('RGB', (512, 512), color='red')
            img.save(test_image_path)
            print_status(f"åˆ›å»ºæµ‹è¯•å›¾ç‰‡: {test_image_path}", "info")
        except ImportError:
            print_status("PIL æœªå®‰è£…ï¼Œè·³è¿‡å›¾ç‰‡ç”Ÿæˆæµ‹è¯•", "warning")
            return False
    
    # è¯»å–å¹¶ç¼–ç å›¾ç‰‡
    with open(test_image_path, 'rb') as f:
        image_data = base64.b64encode(f.read()).decode()
    
    mime_type = "image/png" if test_image_path.endswith('.png') else "image/jpeg"
    
    print_status(f"æµ‹è¯•å›¾ç‰‡: {test_image_path}", "info")
    print_status(f"å›¾ç‰‡å¤§å°: {len(image_data)} bytes (base64)", "info")
    
    # æ„å»º prompt
    prompt_text = """Transform this portrait photo into a professional business portrait.
    
Requirements:
- Change clothing to a professional business suit
- Replace background with a clean gray studio background
- Maintain the person's face exactly as in the original
- High quality, professional lighting
- 3:4 aspect ratio

IMPORTANT: Generate a completely new image, do not return the original."""
    
    # æ„å»º payload
    if config['api_format'] == 'gemini':
        payload = {
            "contents": [{
                "parts": [
                    {"text": prompt_text},
                    {"inline_data": {"mime_type": mime_type, "data": image_data}}
                ]
            }],
            "generationConfig": {
                "temperature": 0.9,
                "responseModalities": ["IMAGE"],
                "aspectRatio": "3:4"
            }
        }
    else:
        # OpenAI æ ¼å¼ - è¿™é‡Œå¯èƒ½æ˜¯é—®é¢˜æ‰€åœ¨ï¼
        payload = {
            "model": config['model_name'],
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt_text},
                        {"type": "image_url", "image_url": {"url": f"data:{mime_type};base64,{image_data}"}}
                    ]
                }
            ],
            "temperature": 0.9,
            "max_tokens": 4096
            # æ³¨æ„ï¼šç§»é™¤äº† strength å‚æ•°ï¼Œå› ä¸º OpenAI æ ¼å¼å¯èƒ½ä¸æ”¯æŒ
        }
    
    print_status(f"ä½¿ç”¨ {config['api_format'].upper()} æ ¼å¼å‘é€è¯·æ±‚", "info")
    
    try:
        headers = {
            'Authorization': f'Bearer {config["api_key"]}',
            'Content-Type': 'application/json'
        }
        
        print_status("å‘é€å›¾ç‰‡ç”Ÿæˆè¯·æ±‚...", "info")
        response = requests.post(
            config['api_url'],
            headers=headers,
            json=payload,
            timeout=120
        )
        
        print_status(f"å“åº”çŠ¶æ€ç : {response.status_code}", 
                    "success" if response.status_code == 200 else "error")
        
        if response.status_code != 200:
            print_status(f"é”™è¯¯: {response.text[:500]}", "error")
            return False
        
        # è§£æå“åº”
        result = response.json()
        print_status(f"å“åº”é”®: {list(result.keys())}", "info")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾ç‰‡æ•°æ®
        has_image = False
        image_source = None
        
        # æ£€æŸ¥ OpenAI æ ¼å¼
        if 'choices' in result and len(result['choices']) > 0:
            choice = result['choices'][0]
            if 'message' in choice:
                content = choice['message'].get('content', '')
                if isinstance(content, str):
                    print_status(f"Content é•¿åº¦: {len(content)}", "info")
                    print_status(f"Content å‰100å­—ç¬¦: {content[:100]}", "info")
                    
                    if content.startswith('data:image') and 'base64' in content:
                        has_image = True
                        image_source = "OpenAI base64"
                        
                        # ä¿å­˜å›¾ç‰‡
                        base64_data = content.split('base64,')[-1]
                        image_bytes = base64.b64decode(base64_data)
                        output_path = "test_output.png"
                        with open(output_path, 'wb') as f:
                            f.write(image_bytes)
                        print_status(f"âœ“ å›¾ç‰‡å·²ä¿å­˜: {output_path} ({len(image_bytes)} bytes)", "success")
                    else:
                        print_status("å“åº”ä¸åŒ…å« base64 å›¾ç‰‡æ•°æ®", "warning")
                        print_status(f"Content ç±»å‹: {content[:50]}...", "warning")
        
        # æ£€æŸ¥ Gemini æ ¼å¼
        elif 'candidates' in result:
            for candidate in result['candidates']:
                if 'content' in candidate and 'parts' in candidate['content']:
                    for part in candidate['content']['parts']:
                        inline_data = part.get('inlineData') or part.get('inline_data')
                        if inline_data and 'data' in inline_data:
                            has_image = True
                            image_source = "Gemini inlineData"
                            
                            image_bytes = base64.b64decode(inline_data['data'])
                            output_path = "test_output.png"
                            with open(output_path, 'wb') as f:
                                f.write(image_bytes)
                            print_status(f"âœ“ å›¾ç‰‡å·²ä¿å­˜: {output_path} ({len(image_bytes)} bytes)", "success")
        
        if not has_image:
            print_status("æœªæ£€æµ‹åˆ°å›¾ç‰‡æ•°æ®ï¼", "error")
            print_status(f"å®Œæ•´å“åº”: {json.dumps(result, indent=2)[:1000]}", "warning")
            return False
        
        print_status(f"å›¾ç‰‡æ¥æº: {image_source}", "success")
        return True
        
    except Exception as e:
        print_status(f"æµ‹è¯•å¤±è´¥: {e}", "error")
        import traceback
        print(traceback.format_exc())
        return False

def check_model_support(config):
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒå›¾åƒç”Ÿæˆ"""
    print("\n" + "="*70)
    print("ğŸ” æ£€æŸ¥æ¨¡å‹æ”¯æŒ")
    print("="*70)
    
    model_name = config['model_name']
    
    # å·²çŸ¥çš„æ”¯æŒå›¾åƒç”Ÿæˆçš„æ¨¡å‹
    supported_models = [
        'gemini-3-pro-image-preview',
        'gemini-3-pro-image-preview-2k',
        'gemini-2.0-flash-exp',
        'gpt-4o',
        'gpt-4o-mini'
    ]
    
    if model_name in supported_models:
        print_status(f"æ¨¡å‹ {model_name} å·²çŸ¥æ”¯æŒå›¾åƒç”Ÿæˆ", "success")
    else:
        print_status(f"æ¨¡å‹ {model_name} å¯èƒ½ä¸æ”¯æŒå›¾åƒç”Ÿæˆ", "warning")
        print_status("å»ºè®®ä½¿ç”¨: gemini-3-pro-image-preview", "info")
    
    # æ£€æŸ¥ API æä¾›å•†å’Œæ¨¡å‹çš„å…¼å®¹æ€§
    api_provider = os.getenv('API_PROVIDER', 'apicore')
    
    if api_provider == 'apicore' and model_name.startswith('gemini'):
        print_status("apicore + Gemini æ¨¡å‹ç»„åˆåº”è¯¥æ”¯æŒå›¾åƒç”Ÿæˆ", "success")
    elif api_provider == '12ai' and model_name.startswith('gemini'):
        print_status("12ai + Gemini æ¨¡å‹ç»„åˆï¼Œä½¿ç”¨åŸç”Ÿ Gemini API", "success")
    else:
        print_status(f"{api_provider} + {model_name} ç»„åˆçš„å…¼å®¹æ€§æœªçŸ¥", "warning")

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "ğŸš€"*35)
    print("  API è°ƒç”¨è¯Šæ–­å·¥å…·")
    print("ğŸš€"*35)
    
    # 1. æ£€æŸ¥é…ç½®
    config = check_api_config()
    if not config:
        print_status("é…ç½®æ£€æŸ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡", "error")
        sys.exit(1)
    
    # 2. æµ‹è¯•è¿æ¥
    if not test_api_connection(config):
        print_status("API è¿æ¥æµ‹è¯•å¤±è´¥", "error")
        # ç»§ç»­æ‰§è¡Œå…¶ä»–æµ‹è¯•
    
    # 3. æ£€æŸ¥æ¨¡å‹æ”¯æŒ
    check_model_support(config)
    
    # 4. æµ‹è¯•å›¾ç‰‡ç”Ÿæˆ
    print("\næ˜¯å¦æµ‹è¯•å›¾ç‰‡ç”Ÿæˆ? (y/n): ", end='')
    choice = input().strip().lower()
    if choice == 'y':
        test_image_generation(config)
    
    print("\n" + "="*70)
    print("è¯Šæ–­å®Œæˆï¼")
    print("="*70)
    print("\nå¸¸è§é—®é¢˜:")
    print("1. å¦‚æœ API è¿”å› 200 ä½†æ²¡æœ‰å›¾ç‰‡æ•°æ®ï¼Œå¯èƒ½æ˜¯æ¨¡å‹ä¸æ”¯æŒå›¾åƒç”Ÿæˆ")
    print("2. å¦‚æœè¿”å›åŸå›¾ï¼Œå¯èƒ½æ˜¯ API å¿½ç•¥äº†ç”ŸæˆæŒ‡ä»¤")
    print("3. å»ºè®®å°è¯•æ›´æ¢æ¨¡å‹æˆ– API æä¾›å•†")

if __name__ == '__main__':
    main()
